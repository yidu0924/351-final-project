---
layout: default
title: Home
permalink: /
---

# Remote Photoplethysmography (rPPG)
## Contactless Heart Rate Estimation from Facial Videos
---

##  Team Members

- **Yi Du** - yidu@umich.edu
- **Lingxiao Yang** - yanglx@umich.edu
- **Yijie Liao** - lyjie@umich.edu

**Course**: EECS 351 - Digital Signal Processing  
**Institution**: University of Michigan  
**Semester**: Fall 2025

---
## Abstract

Traditional heart rate (HR) and photoplethysmography (PPG) measurements rely on contact sensors
(e.g., fingertip or wrist-based optical sensors), which can be uncomfortable or impractical in long-term or
non-cooperative scenarios (e.g., sleep monitoring, driver attention tracking). Remote photoplethysmog-
raphy (rPPG) offers a contactless alternative by estimating blood volume pulse signals from subtle skin
color changes in facial videos. However, rPPG signals are often corrupted by motion artifacts, lighting
variations, and low signal-to-noise ratio (SNR). This project aims to develop a robust rPPG extraction
pipeline using advanced signal processing and machine learning (ML) techniques to accurately estimate
HR and reconstruct the underlying PPG waveform from facial videos under realistic conditions.

## Code Repo
[https://github.com/Lingxiao-Yang/EECS351-rPPG](https://github.com/Lingxiao-Yang/EECS351-rPPG)


## Datasets

We use two public rPPG datasets with synchronized videos + physiological signals:

### **UBFC-rPPG**
- 42 subjects  
- 30 fps  
- Natural illumination  
- Ground-truth finger PPG

### **PURE**
- 10 subjects  
- Controlled motion (steady, rotation, talking)  
- Stable lighting  

---

<div class="note">
<strong> Note:</strong> This project is part of the EECS 351 coursework at the University of Michigan. All work is original and conducted in accordance with academic integrity policies.
</div>

---

*Last Updated: November 17, 2025*
